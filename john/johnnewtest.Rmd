---
title: "Untitled"
output: html_document
---

Let's try this out with john's data at time point 19, and not do the centering:

```{r}
x <- read.table("~/Dropbox/john/s1table.txt", header = TRUE)
y=x[,-c(1,2)]
anno <- read.table("~/Dropbox/john/annotation.txt", header = TRUE, stringsAsFactors = FALSE)
head(anno)

df_ordered <- y[, order(anno$time, anno$bact, anno$ind)]
anno_ordered <- anno[order(anno$time, anno$bact, anno$ind), ]

eighteenguys=which(anno_ordered$time==18&anno_ordered$bact!="none")

anno_ordered=anno_ordered[eighteenguys,]
df_ordered=df_ordered[,eighteenguys]
##we transpose so rows are indiviudals


samplesbygenes=t(df_ordered)

ID=with(anno_ordered,interaction(time,bact),drop=T)
m=model.matrix(~as.factor(ID)-1)

##check sample id matches strain and time
rownames(samplesbygenes)[10]
which(m[10,]==1)
```

Now we compute the average for each subgroup of the uncentered read counts at each gene. Here, voom_class_adj will not acutally be adjusted byt the mean.

```{r, echo=FALSE}
voom_class_adj=samplesbygenes

beta=matrix(NA,nrow = dim(voom_class_adj)[2],ncol=dim(m)[2])##make this the J genes by k subgroup betas
se=matrix(NA,nrow = dim(voom_class_adj)[2],ncol=dim(m)[2])
t=matrix(NA,nrow = dim(voom_class_adj)[2],ncol=dim(m)[2])
colnames(se)=colnames(beta)=colnames(t)=as.matrix(levels(ID))
for(k in 1:ncol(m)){
  fit=lm((voom_class_adj)~(m[,k]-1))
  a=matrix(unlist(coef(summary(fit))),byrow = T,nrow=ncol(voom_class_adj))
  beta[,k]=a[,1]
  se[,k]=a[,2]
  t[,k]=a[,3]
}



write.table(beta,"betafitunadjust.txt",col.names = T)
write.table(se,"sefitunadjust.txt",col.names = T)
write.table(t,"tfitunadjust.txt",col.names = T)

##check to make sure

summary(lm(voom_class_adj[,37]~m[,8]-1))##model the expression of gene 37 on factor 9
t[37,8]
##show that beta is equal to the mean for those individuals

mean(voom_class_adj[which(m[,8]==1),37])##mean gene expression for time point 18 individuals at gene 37
b[37,8]

```

Now we compute factors on the centered T statistics:

```{r}

b=read.table("betafitunadjust.txt")
se=read.table("sefitunadjust.txt")
t=read.table("tfitunadjust.txt")

###You can see uncentered###
hist(as.matrix(b))
R=ncol(t)
L=diag(R)-1/R*as.vector(rep(1,R))%*%t(as.vector(rep(1,R)))
s.j=se/se
tcenteredfull=t(L%*%t(t))
hist(tcenteredfull)
dim(tcenteredfull)

###this should be of the same dimension as v, so use the full projection matrix

index=which(rowSums(abs(tcenteredfull)>2)>0)
strongprojectedt=t(L%*%t(t[index,]))
##check to make sure rowSums 0
rowSums(strongprojectedt)[1:10]

write.table(strongprojectedt,"strongprojectedt.txt",col.names = F ,row.names = F)
```

Now, we need to project into the centered space to estimate the covariance matrix of the ture deviations, using the full L since $v$ will be R, and not $R-1$.

```{r}
system('/Users/sarahurbut/miniconda3/bin/sfa -gen strongprojectedt.txt -g 858 -k 5 -n 8 i -o johnnobaseline')
A="johnnobaseline"

factor.mat=as.matrix(read.table("johnnobaseline_F.out"))
lambda.mat=as.matrix(read.table("johnnobaseline_lambda.out"))

initlist=init.covmat.single.with.projection(t.stat = strongprojectedt,factor.mat = factor.mat,lambda.mat = lambda.mat,Q = 5,P=3)


##check to see correctly initalised, e.g., empirical covariance of strong projected t, full rank factor mat, and svd.

plot(initlist[1,,],cov(strongprojectedt))
M=nrow(strongprojectedt)
full.rank=lambda.mat%*%factor.mat
plot(initlist[2,,],(t(full.rank)%*%full.rank)/(M-1))

P=3;X.c=apply(strongprojectedt,2,function(x) x-mean(x)) ##Column centered matrix of t statistics
svd.X=svd(X.c)
v=svd.X$v;u=svd.X$u;d=svd.X$d
cov.pc=1/M*v[,1:P]%*%diag(d[1:P])%*%t(u[,1:P])%*%t(v[,1:P]%*%diag(d[1:P])%*%t(u[,1:P]))
plot(cov.pc,initlist[3,,])

q=3
load=as.matrix(lambda.mat[,q])
fact=as.matrix(factor.mat[q,])
rank.prox=load%*%t(fact)
a=(1/(M-1)*(t(rank.prox)%*% rank.prox))
plot(as.matrix(a),as.matrix(initlist[3+q,,]))
```

Great, now let's run Bovy:
Recall that we'll need w to be Mx(R-1) and the initialized covariacne matrices to be RxR, so we will use the full set of deviations to initatlise.
```{r}

L=diag(R)-1/R*as.vector(rep(1,R))%*%t(as.vector(rep(1,R)))
t.stat=(t(L%*%t(t[index,])))
###here will be the ws and lvls
L=L[-1,]
w=t(L%*%t(t))
wmax=w[index,]
dim(wmax)
lvlarray=genlvlarray(s.j = s.j[index,],L = L)
dim(lvlarray)

##and here are the initalizeing t.stats
L=diag(R)-1/R*as.vector(rep(1,R))%*%t(as.vector(rep(1,R)))
t.stat=(t(L%*%t(t[index,])))
dim(t.stat)
##right now this isn't working because of array issue, 
##deconvolution.em.with.bovy(t.stat = t.stat,factor.mat = factor.mat,lambda.mat = lambda.mat,v.j = lvlarray,P = 3,L = L[-1,],Q = 5)
```

Alternatively, we can generate using our old covmat function:
```{r}
library('mash')
allcenteredt=(t(L%*%t(t)))
sjmat=convertstandarderrors(s.j = s.j,L= L)##make this be the standard errors of all
dim(allcenteredt)
dim(sjmat)

maxt=(t(L%*%t(t[index,])))

c=compute.covmat(b.gp.hat = allcenteredt,sebetahat = sjmat,Q = 5,t.stat = maxt,lambda.mat = lambda.mat,P = 3,A = "test",factor.mat = factor.mat,bma = T,zero = T,power = 2)$cov

##you can see that these will all by 8x8##

dim(c[[1]])
```

Now, let's fit the model and compute posteriors:
```{r}
w=data.frame(w)
R=ncol(t)
L=diag(R)-1/R*as.vector(rep(1,R))%*%t(as.vector(rep(1,R)))

compute.hm.train.log.lik.pen.with.L(w,se.train = s.j,covmat = c,A = "test",pen = 1,L = L[-1,])
A="test"
pis=readRDS(paste0("pis",A,".rds"))$pihat
cov=c

for(j in 1:nrow(w)){
  total.quant.per.snp.no.baseline(j = j,covmat = cov,b.gp.hat = w,se.gp.hat = s.j,pis = pis,A = "test",checkpoint = F,L = L[-1,])}


##check

j=137
k=5
se.gp.hat=s.j
L=diag(R)-1/R*as.vector(rep(1,R))%*%t(as.vector(rep(1,R)))
b.gp.hat=w
R=ncol(L)
L=L[-1,]
b.mle=as.vector(t(b.gp.hat[j,]))
K=length(covmat)
R=ncol(L)
V.gp.hat=diag(se.gp.hat[j,])^2
LVL=L%*%V.gp.hat%*%t(L)
tinvlist=lapply(covmat,function(x){solve(LVL+L%*%x%*%t(L))})
mupost=post.mean.with.proj(b.mle = b.mle,tinv = tinvlist[[k]],U.k = cov[[k]],L = L)
covpost=post.cov.with.proj(tinv = tinvlist[[k]],U.k = cov[[k]],L = L)
a=post.array.per.snp.no.baseline(j = j,covmat = cov,b.gp.hat = b.gp.hat,se.gp.hat = s.j,L = L)
all.equal(as.numeric(a$post.means[k,]),as.numeric(mupost))
all.equal(as.numeric(a$post.covs[k,]),diag((covpost)))

LVL=L%*%V.gp.hat%*%t(L)###redfine V.jhat as the marginal varianc of Lchat which is LVL'
LSigL=lapply(covmat,function(x){L%*%x%*%t(L)})##redefine Sigma_p as a list of the variance of Lv (i.e., LUkL')
log.lik.snp=log.lik.func(b.mle,LVL,LSigL)
log.lik.minus.max=log.lik.snp-max(log.lik.snp)
  
exp.vec=exp(log.lik.minus.max)
post.weights=t(exp.vec*pis/sum(exp.vec*pis))
mash.means=read.table("testposterior.means.txt")[,-1]
all.equal(as.numeric(post.weights%*%a$post.means),as.numeric(mash.means[j,]))
```